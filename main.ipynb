{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to run the rudimentary design(without CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary files\n",
    "\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import librosa\n",
    "import moviepy.editor as mp\n",
    "from Components.Phoneme_Extraction import speech2text\n",
    "from Components.p2fa_py3.p2fa import align\n",
    "from Components.Viseme_Extraction import viseme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Datasets/Audio/obamaDeepfake.wav\n",
      "MoviePy - Writing audio in ./Datasets/Audio/obamaDeepfake.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Extract the audio from the input video file\n",
    "\n",
    "# Insert Local Video File Path\n",
    "\n",
    "video_path = \"./Datasets/Video/obamaDeepfake.mp4\"\n",
    "clip = mp.VideoFileClip(video_path)\n",
    "    \n",
    "# Insert Local Audio File Path\n",
    "audio_path = video_path.replace('.mp4', '.wav').replace('Video', 'Audio')\n",
    "print(audio_path)\n",
    "clip.audio.write_audiofile(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
      "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WE'RE ENTERING AN ERA IN WHICH OUR ENEMIES CAN MAKE IT LOOK LIKE ANY ONE IS SAYING ANYTHING AT ANY POINT IN TIME EVEN IF THEY WOULD NEVER SAY THOSE THINGS SO FOR INSTANCE THEY COULD HAVE ME SAY THINGS LIKE I KNOW KILMONGER WAS RIGHT OR BEN CARSON IS IN THE SUNKIM PLACE OR ABOUT THIS SIMPLY PRESIDENT TRUMP IS A TOTAL AND COMPLETE DIPSHIT NOW YOU SEE I WOULD NEVER SAYESE THINGS AT LEAST NOT IN A PUBLIC ADDRESS BUT SOME ONE ELSE WOULD SOME ONE LIKE GORDAN PEAL THIS IS A DANGEROUS TIME MOVING FORWARD WE NEED TO BE MORE VIGILANT WITH WHAT WE TRUST FROM THE INTERNET THAT'S A TIME WHEN WE NEED TO RELY ON TRUSTED NEW SOURCES MAY SOUND BASIC BUT HOW WE MOVE FORWARD IN THE AGE OF INFORMATION ISGOING TO BE THE DIFFERENCE BETWEEN WHETHER WE SURVIVE OR WHETHER WE BECOME SOME KIND OF FUCKED UP DYSTOPIA THANK YOU STAY WOKE BITCHES\n"
     ]
    }
   ],
   "source": [
    "# Converting Audio file to Text\n",
    "\n",
    "transcription = speech2text.speech_transcription(audio_path)\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the variable value to the text file\n",
    "text_path = video_path.replace('.mp4', '.txt').replace('Video', 'Text')\n",
    "\n",
    "with open(text_path, 'w') as file:\n",
    "    file.write(transcription.replace(' ', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling wav file from 44100 to 11025...\n",
      "SKIPPING WORD WE'RE\n",
      "SKIPPING WORD ENTERING\n",
      "SKIPPING WORD AN\n",
      "SKIPPING WORD ERA\n",
      "SKIPPING WORD IN\n",
      "SKIPPING WORD WHICH\n",
      "SKIPPING WORD OUR\n",
      "SKIPPING WORD ENEMIES\n",
      "SKIPPING WORD CAN\n",
      "SKIPPING WORD MAKE\n",
      "SKIPPING WORD IT\n",
      "SKIPPING WORD LOOK\n",
      "SKIPPING WORD LIKE\n",
      "SKIPPING WORD ANY\n",
      "SKIPPING WORD ONE\n",
      "SKIPPING WORD IS\n",
      "SKIPPING WORD SAYING\n",
      "SKIPPING WORD ANYTHING\n",
      "SKIPPING WORD AT\n",
      "SKIPPING WORD ANY\n",
      "SKIPPING WORD POINT\n",
      "SKIPPING WORD IN\n",
      "SKIPPING WORD TIME\n",
      "SKIPPING WORD EVEN\n",
      "SKIPPING WORD IF\n",
      "SKIPPING WORD THEY\n",
      "SKIPPING WORD WOULD\n",
      "SKIPPING WORD NEVER\n",
      "SKIPPING WORD SAY\n",
      "SKIPPING WORD THOSE\n",
      "SKIPPING WORD THINGS\n",
      "SKIPPING WORD SO\n",
      "SKIPPING WORD FOR\n",
      "SKIPPING WORD INSTANCE\n",
      "SKIPPING WORD THEY\n",
      "SKIPPING WORD COULD\n",
      "SKIPPING WORD HAVE\n",
      "SKIPPING WORD ME\n",
      "SKIPPING WORD SAY\n",
      "SKIPPING WORD THINGS\n",
      "SKIPPING WORD LIKE\n",
      "SKIPPING WORD I\n",
      "SKIPPING WORD KNOW\n",
      "SKIPPING WORD KILMONGER\n",
      "SKIPPING WORD WAS\n",
      "SKIPPING WORD RIGHT\n",
      "SKIPPING WORD OR\n",
      "SKIPPING WORD BEN\n",
      "SKIPPING WORD CARSON\n",
      "SKIPPING WORD IS\n",
      "SKIPPING WORD IN\n",
      "SKIPPING WORD THE\n",
      "SKIPPING WORD SUNKIM\n",
      "SKIPPING WORD PLACE\n",
      "SKIPPING WORD OR\n",
      "SKIPPING WORD ABOUT\n",
      "SKIPPING WORD THIS\n",
      "SKIPPING WORD SIMPLY\n",
      "SKIPPING WORD PRESIDENT\n",
      "SKIPPING WORD TRUMP\n",
      "SKIPPING WORD IS\n",
      "SKIPPING WORD A\n",
      "SKIPPING WORD TOTAL\n",
      "SKIPPING WORD AND\n",
      "SKIPPING WORD COMPLETE\n",
      "SKIPPING WORD DIPSHIT\n",
      "SKIPPING WORD NOW\n",
      "SKIPPING WORD YOU\n",
      "SKIPPING WORD SEE\n",
      "SKIPPING WORD I\n",
      "SKIPPING WORD WOULD\n",
      "SKIPPING WORD NEVER\n",
      "SKIPPING WORD SAYESE\n",
      "SKIPPING WORD THINGS\n",
      "SKIPPING WORD AT\n",
      "SKIPPING WORD LEAST\n",
      "SKIPPING WORD NOT\n",
      "SKIPPING WORD IN\n",
      "SKIPPING WORD A\n",
      "SKIPPING WORD PUBLIC\n",
      "SKIPPING WORD ADDRESS\n",
      "SKIPPING WORD BUT\n",
      "SKIPPING WORD SOME\n",
      "SKIPPING WORD ONE\n",
      "SKIPPING WORD ELSE\n",
      "SKIPPING WORD WOULD\n",
      "SKIPPING WORD SOME\n",
      "SKIPPING WORD ONE\n",
      "SKIPPING WORD LIKE\n",
      "SKIPPING WORD GORDAN\n",
      "SKIPPING WORD PEAL\n",
      "SKIPPING WORD THIS\n",
      "SKIPPING WORD IS\n",
      "SKIPPING WORD A\n",
      "SKIPPING WORD DANGEROUS\n",
      "SKIPPING WORD TIME\n",
      "SKIPPING WORD MOVING\n",
      "SKIPPING WORD FORWARD\n",
      "SKIPPING WORD WE\n",
      "SKIPPING WORD NEED\n",
      "SKIPPING WORD TO\n",
      "SKIPPING WORD BE\n",
      "SKIPPING WORD MORE\n",
      "SKIPPING WORD VIGILANT\n",
      "SKIPPING WORD WITH\n",
      "SKIPPING WORD WHAT\n",
      "SKIPPING WORD WE\n",
      "SKIPPING WORD TRUST\n",
      "SKIPPING WORD FROM\n",
      "SKIPPING WORD THE\n",
      "SKIPPING WORD INTERNET\n",
      "SKIPPING WORD THAT'S\n",
      "SKIPPING WORD A\n",
      "SKIPPING WORD TIME\n",
      "SKIPPING WORD WHEN\n",
      "SKIPPING WORD WE\n",
      "SKIPPING WORD NEED\n",
      "SKIPPING WORD TO\n",
      "SKIPPING WORD RELY\n",
      "SKIPPING WORD ON\n",
      "SKIPPING WORD TRUSTED\n",
      "SKIPPING WORD NEW\n",
      "SKIPPING WORD SOURCES\n",
      "SKIPPING WORD MAY\n",
      "SKIPPING WORD SOUND\n",
      "SKIPPING WORD BASIC\n",
      "SKIPPING WORD BUT\n",
      "SKIPPING WORD HOW\n",
      "SKIPPING WORD WE\n",
      "SKIPPING WORD MOVE\n",
      "SKIPPING WORD FORWARD\n",
      "SKIPPING WORD IN\n",
      "SKIPPING WORD THE\n",
      "SKIPPING WORD AGE\n",
      "SKIPPING WORD OF\n",
      "SKIPPING WORD INFORMATION\n",
      "SKIPPING WORD ISGOING\n",
      "SKIPPING WORD TO\n",
      "SKIPPING WORD BE\n",
      "SKIPPING WORD THE\n",
      "SKIPPING WORD DIFFERENCE\n",
      "SKIPPING WORD BETWEEN\n",
      "SKIPPING WORD WHETHER\n",
      "SKIPPING WORD WE\n",
      "SKIPPING WORD SURVIVE\n",
      "SKIPPING WORD OR\n",
      "SKIPPING WORD WHETHER\n",
      "SKIPPING WORD WE\n",
      "SKIPPING WORD BECOME\n",
      "SKIPPING WORD SOME\n",
      "SKIPPING WORD KIND\n",
      "SKIPPING WORD OF\n",
      "SKIPPING WORD FUCKED\n",
      "SKIPPING WORD UP\n",
      "SKIPPING WORD DYSTOPIA\n",
      "SKIPPING WORD THANK\n",
      "SKIPPING WORD YOU\n",
      "SKIPPING WORD STAY\n",
      "SKIPPING WORD WOKE\n",
      "SKIPPING WORD BITCHES\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Reube\\\\AppData\\\\Local\\\\Temp\\\\p2fa\\\\aligned.mlf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-426f960baa85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Perform alignment using P2FA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mphoneme_timestamps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_timestamps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malign\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Extract the timestamps of a specific phoneme\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Reuben\\NITC\\Sem8\\Project Part 2\\deepfake-detection\\Components\\p2fa_py3\\p2fa\\align.py\u001b[0m in \u001b[0;36malign\u001b[1;34m(wavfile, trsfile, outfile, wave_start, wave_end, sr_override, model_path, custom_dict, state_align, verbose)\u001b[0m\n\u001b[0;32m    449\u001b[0m         \u001b[0mstate_alignments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m     \u001b[0m_alignments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_aligned_mlf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_mlf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwave_start\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m     \u001b[0mphoneme_alignments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_alignments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_alignment_lists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_alignments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Reuben\\NITC\\Sem8\\Project Part 2\\deepfake-detection\\Components\\p2fa_py3\\p2fa\\align.py\u001b[0m in \u001b[0;36mread_aligned_mlf\u001b[1;34m(mlffile, SR, wave_start)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;31m# TODO: extract log-likelihood score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmlffile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m     \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Reube\\\\AppData\\\\Local\\\\Temp\\\\p2fa\\\\aligned.mlf'"
     ]
    }
   ],
   "source": [
    "# Phoneme Extraction\n",
    "\n",
    "# Perform alignment using P2FA\n",
    "phoneme_timestamps, word_timestamps, pff = align.align(audio_path, text_path)\n",
    "\n",
    "# Extract the timestamps of a specific phoneme\n",
    "target_phonemes = [\"M\", \"B\", \"P\"] # Closed mouth phonemes that we want to extract\n",
    "for phoneme in target_phonemes:\n",
    "    target_phoneme_timestamps = [(start, end) for p, start, end in phoneme_timestamps if p == phoneme]\n",
    "\n",
    "# Print the timestamps of the target phoneme\n",
    "print(f\"Timestamps of '{phoneme}': {target_phoneme_timestamps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_phoneme_timestamps = [(2.6564625850340136, 2.756235827664399), (3.045578231292517, 3.1054421768707483), (6.248299319727891, 6.318140589569161), (12.30453514739229, 12.414285714285713), (16.315419501133785, 16.345351473922904), (22.840589569160993, 22.89047619047619), (24.52675736961451, 24.576643990929703), (25.48458049886621, 25.544444444444444), (34.384353741496604, 34.42426303854876), (36.040589569161, 36.070521541950114), (41.168934240362816, 41.208843537414964), (43.363945578231295, 43.41383219954648), (44.6609977324263, 44.81065759637188), (46.436961451247164, 46.50680272108844), (48.39251700680273, 48.462358276644), (53.2015873015873, 53.31133786848073), (55.45646258503402, 55.5562358276644), (58.210204081632654, 58.24013605442177), (64.19659863945579, 64.30634920634921), (64.47596371882086, 64.55578231292517)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Viseme Extraction\n",
    "\n",
    "#import libraires\n",
    "import cv2\n",
    "import numpy as np\n",
    "frames=viseme.extract_frames(video_path,target_phoneme_timestamps)\n",
    "\n",
    "# Define the output folder\n",
    "frame_path = \"./Datasets/Viseme_frames\"\n",
    "\n",
    "# Loop through the frames and save them to the output folder\n",
    "for i, frame in enumerate(frames):\n",
    "    cv2.imwrite(frame_path + \"/frame_{}.jpg\".format(i), frame)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f5583cf1d9466b5c27e75c89cc6b383bed5736d6b16c51c8074d8690011a952"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
