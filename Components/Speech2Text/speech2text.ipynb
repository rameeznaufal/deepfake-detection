{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python code to convert video to audio\n",
    "import moviepy.editor as mp\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import wave\n",
    "from scipy.io import wavfile\n",
    "from IPython.display import Audio\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in ./reuben.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    }
   ],
   "source": [
    "# Insert Local Video File Path \n",
    "clip = mp.VideoFileClip(r\"./reuben_deepfake.mp4\")\n",
    "  \n",
    "# Insert Local Audio File Path\n",
    "clip.audio.write_audiofile(r\"./reuben.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
      "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "more                 from 1.41 sec to 1.83 sec, confidence is 66.42%\n",
      "and                  from 1.83 sec to 2.19 sec, confidence is 100.00%\n",
      "torn                 from 2.19 sec to 2.76 sec, confidence is 100.00%\n",
      "an                   from 2.76 sec to 3.03 sec, confidence is 79.73%\n",
      "hour                 from 3.06 sec to 4.05 sec, confidence is 79.73%\n",
      "the                  from 4.23 sec to 4.41 sec, confidence is 100.00%\n",
      "whole                from 4.41 sec to 4.95 sec, confidence is 100.00%\n",
      "armor                from 4.95 sec to 5.34 sec, confidence is 60.49%\n",
      "mashed               from 5.34 sec to 6.00 sec, confidence is 91.17%\n",
      "but                  from 6.00 sec to 6.55 sec, confidence is 83.27%\n",
      "look                 from 6.60 sec to 7.02 sec, confidence is 52.81%\n",
      "where                from 7.02 sec to 7.38 sec, confidence is 86.14%\n",
      "are                  from 7.56 sec to 8.01 sec, confidence is 89.74%\n",
      "you                  from 8.01 sec to 8.29 sec, confidence is 89.74%\n",
      "i'm                  from 8.29 sec to 8.64 sec, confidence is 87.40%\n",
      "sure                 from 8.67 sec to 9.42 sec, confidence is 98.34%\n",
      "yeah                 from 11.37 sec to 11.64 sec, confidence is 82.27%\n",
      "as                   from 13.86 sec to 14.25 sec, confidence is 100.00%\n",
      "much                 from 14.28 sec to 14.58 sec, confidence is 59.16%\n",
      "as                   from 15.12 sec to 15.45 sec, confidence is 100.00%\n",
      "of                   from 15.45 sec to 15.57 sec, confidence is 71.60%\n",
      "shadows              from 15.57 sec to 16.47 sec, confidence is 68.29%\n",
      "furnish              from 16.47 sec to 17.40 sec, confidence is 64.35%\n",
      "sure                 from 18.84 sec to 19.50 sec, confidence is 79.89%\n",
      "forge                from 22.05 sec to 22.89 sec, confidence is 51.18%\n",
      "judged               from 22.89 sec to 23.50 sec, confidence is 42.70%\n",
      "that                 from 23.50 sec to 23.85 sec, confidence is 87.12%\n",
      "sharp                from 25.20 sec to 25.86 sec, confidence is 81.41%\n",
      "fanged               from 25.89 sec to 26.61 sec, confidence is 54.02%\n",
      "that                 from 26.61 sec to 27.36 sec, confidence is 79.82%\n",
      "i                    from 32.31 sec to 32.49 sec, confidence is 89.52%\n",
      "learned              from 32.49 sec to 33.21 sec, confidence is 84.85%\n",
      "this                 from 33.49 sec to 33.81 sec, confidence is 76.29%\n",
      "one                  from 33.81 sec to 34.44 sec, confidence is 45.83%\n",
      "and                  from 38.61 sec to 39.06 sec, confidence is 84.70%\n",
      "kosher               from 39.09 sec to 39.93 sec, confidence is 75.85%\n",
      "version              from 39.96 sec to 40.47 sec, confidence is 75.85%\n",
      "was                  from 40.47 sec to 40.65 sec, confidence is 100.00%\n",
      "shown                from 40.65 sec to 41.04 sec, confidence is 100.00%\n",
      "to                   from 41.07 sec to 41.31 sec, confidence is 100.00%\n",
      "flash                from 41.38 sec to 42.27 sec, confidence is 38.32%\n",
      "albert               from 44.46 sec to 45.09 sec, confidence is 87.02%\n",
      "and                  from 45.09 sec to 45.21 sec, confidence is 64.86%\n",
      "shell                from 45.24 sec to 45.78 sec, confidence is 84.56%\n",
      "pierre               from 45.78 sec to 46.32 sec, confidence is 90.53%\n",
      "punishment           from 47.76 sec to 48.54 sec, confidence is 100.00%\n",
      "could                from 48.57 sec to 49.20 sec, confidence is 86.97%\n",
      "shift                from 49.44 sec to 49.77 sec, confidence is 81.86%\n",
      "to                   from 49.80 sec to 50.22 sec, confidence is 93.74%\n",
      "less                 from 50.22 sec to 50.70 sec, confidence is 63.25%\n",
      "than                 from 51.18 sec to 51.54 sec, confidence is 63.25%\n",
      "that                 from 51.54 sec to 51.82 sec, confidence is 80.12%\n",
      "oh                   from 54.99 sec to 55.47 sec, confidence is 100.00%\n",
      "shy                  from 57.54 sec to 58.21 sec, confidence is 62.61%\n",
      "as                   from 58.21 sec to 58.46 sec, confidence is 40.99%\n",
      "the                  from 58.46 sec to 58.62 sec, confidence is 59.63%\n",
      "novel                from 58.62 sec to 59.22 sec, confidence is 100.00%\n",
      "shy                  from 59.22 sec to 59.70 sec, confidence is 94.22%\n",
      "stretch              from 60.12 sec to 61.32 sec, confidence is 73.49%\n",
      "shirt                from 63.54 sec to 64.14 sec, confidence is 45.69%\n",
      "with                 from 64.17 sec to 64.38 sec, confidence is 74.87%\n",
      "peggy                from 64.38 sec to 64.80 sec, confidence is 30.00%\n",
      "to                   from 64.84 sec to 65.04 sec, confidence is 90.18%\n",
      "quash                from 65.07 sec to 65.94 sec, confidence is 98.24%\n",
      "that                 from 66.03 sec to 66.60 sec, confidence is 100.00%\n",
      "sugar                from 68.37 sec to 68.88 sec, confidence is 48.62%\n",
      "rush                 from 68.91 sec to 69.63 sec, confidence is 48.62%\n",
      "shared               from 71.58 sec to 72.20 sec, confidence is 37.36%\n",
      "yeah                 from 75.15 sec to 75.42 sec, confidence is 54.88%\n",
      "cool                 from 75.51 sec to 76.20 sec, confidence is 36.31%\n",
      "shut                 from 80.22 sec to 80.79 sec, confidence is 94.42%\n",
      "down                 from 80.82 sec to 81.30 sec, confidence is 94.42%\n",
      "horse                from 81.30 sec to 81.78 sec, confidence is 100.00%\n",
      "trail                from 81.78 sec to 82.53 sec, confidence is 100.00%\n",
      "live                 from 86.76 sec to 87.15 sec, confidence is 66.02%\n",
      "and                  from 87.15 sec to 87.36 sec, confidence is 92.71%\n",
      "food                 from 87.39 sec to 88.08 sec, confidence is 100.00%\n",
      "an                   from 89.28 sec to 89.81 sec, confidence is 68.36%\n",
      "old                  from 89.82 sec to 90.12 sec, confidence is 37.00%\n",
      "factory              from 90.15 sec to 91.02 sec, confidence is 100.00%\n",
      "with                 from 91.08 sec to 91.39 sec, confidence is 100.00%\n",
      "the                  from 91.41 sec to 92.01 sec, confidence is 72.23%\n",
      "forceful             from 92.07 sec to 93.09 sec, confidence is 70.37%\n",
      "habit                from 93.12 sec to 93.87 sec, confidence is 100.00%\n",
      "charm                from 96.00 sec to 97.14 sec, confidence is 95.61%\n",
      "the                  from 98.16 sec to 99.27 sec, confidence is 86.04%\n",
      "question             from 100.38 sec to 101.22 sec, confidence is 100.00%\n",
      "should               from 101.70 sec to 102.12 sec, confidence is 100.00%\n",
      "wash                 from 102.12 sec to 102.90 sec, confidence is 100.00%\n",
      "show                 from 106.71 sec to 107.31 sec, confidence is 100.00%\n",
      "that                 from 107.34 sec to 107.64 sec, confidence is 40.57%\n",
      "shit                 from 107.67 sec to 108.30 sec, confidence is 40.57%\n",
      "that                 from 109.65 sec to 109.92 sec, confidence is 92.30%\n",
      "whole                from 109.92 sec to 110.55 sec, confidence is 74.81%\n",
      "scene                from 111.27 sec to 112.11 sec, confidence is 66.58%\n",
      "ah                   from 115.14 sec to 115.56 sec, confidence is 49.45%\n",
      "come                 from 115.59 sec to 115.89 sec, confidence is 53.93%\n",
      "on                   from 115.89 sec to 116.10 sec, confidence is 65.75%\n",
      "flash                from 116.10 sec to 116.94 sec, confidence is 82.10%\n",
      "she                  from 119.40 sec to 120.09 sec, confidence is 45.26%\n",
      "added                from 121.20 sec to 121.53 sec, confidence is 45.26%\n",
      "that                 from 121.53 sec to 121.85 sec, confidence is 45.71%\n",
      "our                  from 122.07 sec to 122.28 sec, confidence is 60.62%\n",
      "phones               from 122.28 sec to 122.70 sec, confidence is 77.78%\n",
      "patrol               from 122.70 sec to 123.15 sec, confidence is 99.48%\n",
      "on                   from 123.15 sec to 123.48 sec, confidence is 92.40%\n",
      "the                  from 123.51 sec to 123.87 sec, confidence is 97.84%\n",
      "national             from 123.87 sec to 124.54 sec, confidence is 100.00%\n",
      "birth                from 124.54 sec to 125.64 sec, confidence is 42.63%\n",
      "while                from 126.72 sec to 127.65 sec, confidence is 90.33%\n",
      "the                  from 128.01 sec to 128.16 sec, confidence is 50.76%\n",
      "whole                from 128.22 sec to 128.64 sec, confidence is 55.27%\n",
      "show                 from 128.64 sec to 129.15 sec, confidence is 100.00%\n",
      "turbans              from 129.18 sec to 129.89 sec, confidence is 73.41%\n",
      "said                 from 129.89 sec to 130.59 sec, confidence is 83.90%\n",
      "the                  from 130.65 sec to 131.04 sec, confidence is 100.00%\n",
      "trash                from 131.10 sec to 131.53 sec, confidence is 27.76%\n",
      "sry                  from 136.83 sec to 137.49 sec, confidence is 30.14%\n",
      "loot                 from 137.54 sec to 138.09 sec, confidence is 92.34%\n",
      "the                  from 138.15 sec to 138.39 sec, confidence is 99.88%\n",
      "crash                from 138.39 sec to 138.99 sec, confidence is 85.16%\n"
     ]
    }
   ],
   "source": [
    "import wave\n",
    "import json\n",
    "\n",
    "from vosk import Model, KaldiRecognizer, SetLogLevel\n",
    "import Word as custom_Word\n",
    "\n",
    "model_path = \"vosk-model-en-us-0.21\"\n",
    "audio_filename = \"transcript.wav\"\n",
    "\n",
    "model = Model(model_path)\n",
    "wf = wave.open(audio_filename, \"rb\")\n",
    "rec = KaldiRecognizer(model, wf.getframerate())\n",
    "rec.SetWords(True)\n",
    "\n",
    "# get the list of JSON dictionaries\n",
    "results = []\n",
    "# recognize speech using vosk model\n",
    "while True:\n",
    "    data = wf.readframes(4000)\n",
    "    if len(data) == 0:\n",
    "        break\n",
    "    if rec.AcceptWaveform(data):\n",
    "        part_result = json.loads(rec.Result())\n",
    "        results.append(part_result)\n",
    "part_result = json.loads(rec.FinalResult())\n",
    "results.append(part_result)\n",
    "\n",
    "# convert list of JSON dictionaries to list of 'Word' objects\n",
    "list_of_Words = []\n",
    "for sentence in results:\n",
    "    if len(sentence) == 1:\n",
    "        # sometimes there are bugs in recognition \n",
    "        # and it returns an empty dictionary\n",
    "        # {'text': ''}\n",
    "        continue\n",
    "    for obj in sentence['result']:\n",
    "        w = custom_Word.Word(obj)  # create custom Word object\n",
    "        list_of_Words.append(w)  # and add it to list\n",
    "\n",
    "wf.close()  # close audiofile\n",
    "\n",
    "# output to the screen\n",
    "for word in list_of_Words:\n",
    "    print(word.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result2:\n",
      "{   'alternative': [   {   'confidence': 0.8600024,\n",
      "                           'transcript': 'entering an error which are Enemies '\n",
      "                                         'committed look like anyone is saying '\n",
      "                                         'anything have me say things like '\n",
      "                                         'now'},\n",
      "                       {   'transcript': 'which are Enemies committed look '\n",
      "                                         'like anyone is saying anything have '\n",
      "                                         'me say things like now'},\n",
      "                       {   'transcript': 'entering an error which are Enemies '\n",
      "                                         'committed look like anyone saying '\n",
      "                                         'anything have me say things like '\n",
      "                                         'now'},\n",
      "                       {   'transcript': 'entering an error which are Enemies '\n",
      "                                         'committed look like anyone is saying '\n",
      "                                         'anything have me say things like now '\n",
      "                                         'in Assam'}],\n",
      "    'final': True}\n",
      "result2:\n",
      "{   'alternative': [   {   'confidence': 0.84630013,\n",
      "                           'transcript': 'someone we need to be more which we '\n",
      "                                         'trust from Yamuna trusted new '\n",
      "                                         'sources'},\n",
      "                       {   'transcript': 'spanks someone else someone we need '\n",
      "                                         'to be more which we trust from '\n",
      "                                         'Yamuna trusted new sources'},\n",
      "                       {   'transcript': 'someone else someone we need to be '\n",
      "                                         'more which we trust from Yamuna '\n",
      "                                         'trusted new sources'},\n",
      "                       {   'transcript': 'someone we need to be more which we '\n",
      "                                         'trust from Yamuna'},\n",
      "                       {   'transcript': 'spanks someone else someone we need '\n",
      "                                         'to be more which we trust from '\n",
      "                                         'Yamuna'}],\n",
      "    'final': True}\n",
      "result2:\n",
      "{   'alternative': [   {   'confidence': 0.87995279,\n",
      "                           'transcript': 'Ganpati defence between whatever we '\n",
      "                                         'become some kind of fuck up to stop '\n",
      "                                         'here thank you'},\n",
      "                       {   'transcript': 'Ganpati defence between whatever we '\n",
      "                                         'become some kind of fuck up to stop '\n",
      "                                         'here thank you stay work pictures'},\n",
      "                       {   'transcript': 'Ganpati defence between whatever '\n",
      "                                         'become some kind of fuck up to stop '\n",
      "                                         'here thank you'},\n",
      "                       {   'transcript': 'Ganpati defence between whatever we '\n",
      "                                         'become some kind of fuck up to stop '\n",
      "                                         'here thank you stay work better'},\n",
      "                       {   'transcript': 'Ganpati defence between whatever '\n",
      "                                         'become some kind of fuck up to stop '\n",
      "                                         'here thank you stay work better'}],\n",
      "    'final': True}\n",
      "result2:\n",
      "[]\n"
     ]
    },
    {
     "ename": "UnknownValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownValueError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-3532a0ee1491>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mtext\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecognize_google\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m             \u001b[0maudio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWaitTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python\\Python38\\lib\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36mrecognize_google\u001b[1;34m(self, audio_data, key, language, pfilter, show_all, with_confidence)\u001b[0m\n\u001b[0;32m    917\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'result2:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    918\u001b[0m         \u001b[0mpprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactual_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 919\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactual_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactual_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"alternative\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mraise\u001b[0m \u001b[0mUnknownValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    920\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    921\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m\"confidence\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactual_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"alternative\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "r = sr.Recognizer()\n",
    "\n",
    "with sr.AudioFile('transcript.wav') as source:\n",
    "    audio = r.record(source, duration=30)\n",
    "    text = \"\"\n",
    "    try:\n",
    "        while True:\n",
    "            text += r.recognize_google(audio)\n",
    "            audio = r.record(source, duration=30)\n",
    "    except sr.WaitTimeoutError:\n",
    "        pass\n",
    "\n",
    "with open('output.txt', 'w') as f:\n",
    "    f.write(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WE'RE ENTERING AN ERA IN WHICH OUR ENEMIES CAN MAKE IT LOOK LIKE ANY ONE IS SAYING ANYTHING AT ANY POINT IN TIME EVEN IF THEY WOULD NEVER SAY THOSE THINGS SO FOR INSTANCE THEY COULD HAVE ME SAY THINGS LIKE I'LL KNOW KILMONGER WAS RIGHT OR BEN CARSON IS IN THE SUNKIN PLACES OR ABOUT THIS SIMPLY PRESIDENT TRUMP IS A TOTAL AND COMPLETE DIPSHIT NOW YOU SEE I WOULD NEVER SAY THESE THINGS AT LEAST NOT IN A PUBLIC ADDRESS BUT SOME ONE ELSE WOULD SOME ONE LIKE GEORGAN PEAL THIS IS A DANGEROUS TIME MOVING FORWARD WE NEED TO BE MORE VIGILANT WITH WHAT WE TRUST FROM THE INNER NET THAT'S A TIME WHEN WE NEED TO RELIVE ON TRUSTED NEW SOURCES MAY SOUND BASIC BUT HOW WE MOVE FORWARD IN THE AGE OF INFORMATION IS GOING TO BE THE DIFFERENCE BETWEEN WHETHER WE SURVIVE OR WHETHER WE BECOME SOME KIND OF FUCKED UP DISTOPIA THANK YOU STAY WOKE BITCHES\n"
     ]
    }
   ],
   "source": [
    "file_name = 'transcript.wav'\n",
    "\n",
    "data = wavfile.read(file_name)\n",
    "framerate = data[0]\n",
    "sounddata = data[1]\n",
    "time = np.arange(0,len(sounddata))/framerate\n",
    "input_audio, _ = librosa.load(file_name, sr=16000)\n",
    "input_values = tokenizer(input_audio, return_tensors=\"pt\").input_values\n",
    "logits = model(input_values).logits\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "transcription = tokenizer.batch_decode(predicted_ids)[0]\n",
    "print(transcription)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result2:\n",
      "{   'alternative': [   {   'confidence': 0.85035503,\n",
      "                           'transcript': 'entering an error which are Enemies '\n",
      "                                         'committed look like anyone is saying '\n",
      "                                         'anything'},\n",
      "                       {   'transcript': 'which are Enemies committed look '\n",
      "                                         'like anyone is saying anything'},\n",
      "                       {   'transcript': 'entering an error which are Enemies '\n",
      "                                         'committed look like anyone is saying '\n",
      "                                         'anything have me say things like '\n",
      "                                         'now'}],\n",
      "    'final': True}\n",
      "entering an error which are Enemies committed look like anyone is saying anything\n",
      "144.94\n",
      "Phoneme 'b', 'm', or 'p' found in word 'Enemies' at 0:55.746\n",
      "Phoneme 'b', 'm', or 'p' found in word 'committed' at 1:6.895\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "# Load the audio file\n",
    "r = sr.Recognizer()\n",
    "audio_file = sr.AudioFile('transcript.wav')\n",
    "with audio_file as source:\n",
    "    audio_data = r.record(source)\n",
    "\n",
    "# Perform speech recognition\n",
    "transcription = r.recognize_google(audio_data)\n",
    "\n",
    "print(transcription)\n",
    "\n",
    "# Split the transcription into words\n",
    "words = transcription.split()\n",
    "\n",
    "# Get the sample rate and number of samples from the audio data\n",
    "sample_rate = audio_data.sample_rate\n",
    "num_samples = len(audio_data.get_raw_data())\n",
    "\n",
    "# Calculate the duration of the audio data\n",
    "duration = num_samples / sample_rate\n",
    "\n",
    "print(duration)\n",
    "\n",
    "# Find the time stamps of the phonemes 'b', 'm', and 'p'\n",
    "for i, word in enumerate(words):\n",
    "    if 'b' in word or 'm' in word or 'p' in word:\n",
    "        word_duration = duration / len(words)\n",
    "        time_stamp = i * word_duration\n",
    "        minutes, seconds = divmod(time_stamp, 60)\n",
    "        milliseconds = int((seconds % 1) * 1000)\n",
    "        print(f\"Phoneme 'b', 'm', or 'p' found in word '{word}' at {int(minutes)}:{int(seconds)}.{milliseconds}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'acoustic_model.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-080770189fd6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mmfccs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maudio_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_mfcc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"acoustic_model.pt\"\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# load a pre-trained acoustic model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmfccs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# add a batch dimension to the inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# run the inputs through the acoustic model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python\\Python38\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m             \u001b[1;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python\\Python38\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python\\Python38\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'acoustic_model.pt'"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "import wave\n",
    "import contextlib\n",
    "\n",
    "filename = 'transcript.wav'\n",
    "\n",
    "with contextlib.closing(wave.open(filename,'r')) as f:\n",
    "    rate, audio_data = wavfile.read(filename)\n",
    "    audio_data = audio_data.T\n",
    "    audio_data = audio_data / np.max(np.abs(audio_data))  # normalize the audio data to the range [-1, 1]\n",
    "\n",
    "    mfccs = librosa.feature.mfcc(y=audio_data, sr=rate, n_mfcc=13)\n",
    "\n",
    "    model = torch.load(\"acoustic_model.pt\")  # load a pre-trained acoustic model\n",
    "    inputs = torch.tensor(mfccs.T).unsqueeze(0)  # add a batch dimension to the inputs\n",
    "    outputs = model(inputs)  # run the inputs through the acoustic model\n",
    "    _, predicted_phonemes = torch.max(outputs, dim=2)  # get the predicted phonemes\n",
    "\n",
    "    for i, predicted_phoneme in enumerate(predicted_phonemes[0]):\n",
    "        if predicted_phoneme == \"M\":  # check if the predicted phoneme is \"M\"\n",
    "            time = i * (len(audio_data) / mfccs.shape[1]) / rate\n",
    "            print(\"Phonetic sound of M found at time: {:.2f} seconds\".format(time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result2:\n",
      "{   'alternative': [   {   'confidence': 0.85986006,\n",
      "                           'transcript': 'entering an error which are Enemies '\n",
      "                                         'committed look like anyone is saying '\n",
      "                                         'anything have me say things like '\n",
      "                                         'now'},\n",
      "                       {   'transcript': 'which are Enemies committed look '\n",
      "                                         'like anyone is saying anything have '\n",
      "                                         'me say things like now'},\n",
      "                       {   'transcript': 'entering an error which are Enemies '\n",
      "                                         'committed look like anyone saying '\n",
      "                                         'anything have me say things like '\n",
      "                                         'now'},\n",
      "                       {   'transcript': 'entering an error which are Enemies '\n",
      "                                         'committed look like anyone is saying '\n",
      "                                         'anything have me say things like now '\n",
      "                                         'information'},\n",
      "                       {   'transcript': 'which are Enemies committed look '\n",
      "                                         'like anyone is saying anything have '\n",
      "                                         'me say things like now information'}],\n",
      "    'final': True}\n",
      "m:\n",
      "\t0.43 - 0.57\n",
      "\t0.22 - 0.34\n",
      "\t0.34 - 0.45\n",
      "\t0.01 - 0.51\n",
      "b:\n",
      "p:\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "# Load the audio file into memory\n",
    "r = sr.Recognizer()\n",
    "with sr.AudioFile('transcript.wav') as source:\n",
    "    audio = r.record(source)\n",
    "\n",
    "# Recognize the speech in the audio file\n",
    "text = r.recognize_google(audio)\n",
    "\n",
    "# Split the text into words\n",
    "words = text.split()\n",
    "\n",
    "# Keep track of the time stamp for each word\n",
    "time_stamps = []\n",
    "start_time = 0\n",
    "for word in words:\n",
    "    end_time = start_time + len(word) / 11025 # Assuming a sample rate of 11025 Hz\n",
    "    time_stamps.append((start_time, end_time))\n",
    "    start_time = end_time\n",
    "\n",
    "# Look for occurrences of \"m\", \"b\", and \"p\"\n",
    "letter_time_stamps = {}\n",
    "for letter in \"mbp\":\n",
    "    letter_time_stamps[letter] = []\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    for j, char in enumerate(word):\n",
    "        if char.lower() in \"mbp\":\n",
    "            letter_time_stamps[char.lower()].append(\n",
    "                (time_stamps[i][0] + j / len(word), time_stamps[i][0] + (j + 1) / len(word))\n",
    "            )\n",
    "\n",
    "# Print the time stamps for each letter\n",
    "for letter, stamps in letter_time_stamps.items():\n",
    "    print(f\"{letter}:\")\n",
    "    for start, end in stamps:\n",
    "        print(f\"\\t{start:.2f} - {end:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b081a66ee97bd2b6a16f43955f1d810b7ea816d6eaeb65e157ef9e038445f0c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
