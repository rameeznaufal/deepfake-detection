{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to run the rudimentary design(without CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-05 05:41:41.705679: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-05 05:41:48.893094: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/rameez/Final_Proj/deepfake-detection/venv/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-03-05 05:41:48.893126: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-05 05:42:01.976407: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/rameez/Final_Proj/deepfake-detection/venv/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-03-05 05:42:01.976982: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/rameez/Final_Proj/deepfake-detection/venv/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-03-05 05:42:01.977016: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Import all necessary files\n",
    "\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import librosa\n",
    "# import cv2\n",
    "import os\n",
    "import moviepy.editor as mp\n",
    "from Components.Phoneme_Extraction import speech2text\n",
    "from Components.p2fa_py3.p2fa import align\n",
    "from Components.Viseme_Extraction import viseme\n",
    "from Components.Mouth_Labelling import mouthLabelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "MoviePy error: failed to read the duration of file ./Datasets/Video/obamaDeepfake.mp4.\nHere are the file infos returned by ffmpeg:\n\nffmpeg version 4.2.2-static https://johnvansickle.com/ffmpeg/  Copyright (c) 2000-2019 the FFmpeg developers\n  built with gcc 8 (Debian 8.3.0-6)\n  configuration: --enable-gpl --enable-version3 --enable-static --disable-debug --disable-ffplay --disable-indev=sndio --disable-outdev=sndio --cc=gcc --enable-fontconfig --enable-frei0r --enable-gnutls --enable-gmp --enable-libgme --enable-gray --enable-libaom --enable-libfribidi --enable-libass --enable-libvmaf --enable-libfreetype --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-librubberband --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libvorbis --enable-libopus --enable-libtheora --enable-libvidstab --enable-libvo-amrwbenc --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libdav1d --enable-libxvid --enable-libzvbi --enable-libzimg\n  libavutil      56. 31.100 / 56. 31.100\n  libavcodec     58. 54.100 / 58. 54.100\n  libavformat    58. 29.100 / 58. 29.100\n  libavdevice    58.  8.100 / 58.  8.100\n  libavfilter     7. 57.100 /  7. 57.100\n  libswscale      5.  5.100 /  5.  5.100\n  libswresample   3.  5.100 /  3.  5.100\n  libpostproc    55.  5.100 / 55.  5.100\n[mov,mp4,m4a,3gp,3g2,mj2 @ 0x6936480] Format mov,mp4,m4a,3gp,3g2,mj2 detected only with low score of 1, misdetection possible!\n[mov,mp4,m4a,3gp,3g2,mj2 @ 0x6936480] moov atom not found\n./Datasets/Video/obamaDeepfake.mp4: Invalid data found when processing input\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/Final_Proj/deepfake-detection/venv/lib/python3.8/site-packages/moviepy/video/io/ffmpeg_reader.py:285\u001b[0m, in \u001b[0;36mffmpeg_parse_infos\u001b[0;34m(filename, print_infos, check_duration, fps_source)\u001b[0m\n\u001b[1;32m    284\u001b[0m index \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m is_GIF \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 285\u001b[0m line \u001b[39m=\u001b[39m [l \u001b[39mfor\u001b[39;49;00m l \u001b[39min\u001b[39;49;00m lines \u001b[39mif\u001b[39;49;00m keyword \u001b[39min\u001b[39;49;00m l][index]\n\u001b[1;32m    286\u001b[0m match \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39mfindall(\u001b[39m\"\u001b[39m\u001b[39m([0-9][0-9]:[0-9][0-9]:[0-9][0-9].[0-9][0-9])\u001b[39m\u001b[39m\"\u001b[39m, line)[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Extract the audio from the input video file\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[39m# Insert Local Video File Path\u001b[39;00m\n\u001b[1;32m      5\u001b[0m video_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m./Datasets/Video/obamaDeepfake.mp4\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m clip \u001b[39m=\u001b[39m mp\u001b[39m.\u001b[39;49mVideoFileClip(video_path)\n\u001b[1;32m      8\u001b[0m \u001b[39m# Insert Local Audio File Path\u001b[39;00m\n\u001b[1;32m      9\u001b[0m audio_path \u001b[39m=\u001b[39m video_path\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m.mp4\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m.wav\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39mVideo\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAudio\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Final_Proj/deepfake-detection/venv/lib/python3.8/site-packages/moviepy/video/io/VideoFileClip.py:88\u001b[0m, in \u001b[0;36mVideoFileClip.__init__\u001b[0;34m(self, filename, has_mask, audio, audio_buffersize, target_resolution, resize_algorithm, audio_fps, audio_nbytes, verbose, fps_source)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[39m# Make a reader\u001b[39;00m\n\u001b[1;32m     87\u001b[0m pix_fmt \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrgba\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m has_mask \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mrgb24\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 88\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreader \u001b[39m=\u001b[39m FFMPEG_VideoReader(filename, pix_fmt\u001b[39m=\u001b[39;49mpix_fmt,\n\u001b[1;32m     89\u001b[0m                                  target_resolution\u001b[39m=\u001b[39;49mtarget_resolution,\n\u001b[1;32m     90\u001b[0m                                  resize_algo\u001b[39m=\u001b[39;49mresize_algorithm,\n\u001b[1;32m     91\u001b[0m                                  fps_source\u001b[39m=\u001b[39;49mfps_source)\n\u001b[1;32m     93\u001b[0m \u001b[39m# Make some of the reader's attributes accessible from the clip\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mduration \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreader\u001b[39m.\u001b[39mduration\n",
      "File \u001b[0;32m~/Final_Proj/deepfake-detection/venv/lib/python3.8/site-packages/moviepy/video/io/ffmpeg_reader.py:35\u001b[0m, in \u001b[0;36mFFMPEG_VideoReader.__init__\u001b[0;34m(self, filename, print_infos, bufsize, pix_fmt, check_duration, target_resolution, resize_algo, fps_source)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilename \u001b[39m=\u001b[39m filename\n\u001b[1;32m     34\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproc \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m infos \u001b[39m=\u001b[39m ffmpeg_parse_infos(filename, print_infos, check_duration,\n\u001b[1;32m     36\u001b[0m                            fps_source)\n\u001b[1;32m     37\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfps \u001b[39m=\u001b[39m infos[\u001b[39m'\u001b[39m\u001b[39mvideo_fps\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     38\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize \u001b[39m=\u001b[39m infos[\u001b[39m'\u001b[39m\u001b[39mvideo_size\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/Final_Proj/deepfake-detection/venv/lib/python3.8/site-packages/moviepy/video/io/ffmpeg_reader.py:289\u001b[0m, in \u001b[0;36mffmpeg_parse_infos\u001b[0;34m(filename, print_infos, check_duration, fps_source)\u001b[0m\n\u001b[1;32m    287\u001b[0m         result[\u001b[39m'\u001b[39m\u001b[39mduration\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m cvsecs(match)\n\u001b[1;32m    288\u001b[0m     \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m--> 289\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m((\u001b[39m\"\u001b[39m\u001b[39mMoviePy error: failed to read the duration of file \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    290\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39mHere are the file infos returned by ffmpeg:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m)\u001b[39m%\u001b[39m(\n\u001b[1;32m    291\u001b[0m                           filename, infos))\n\u001b[1;32m    293\u001b[0m \u001b[39m# get the output line that speaks about video\u001b[39;00m\n\u001b[1;32m    294\u001b[0m lines_video \u001b[39m=\u001b[39m [l \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lines \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m Video: \u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m l \u001b[39mand\u001b[39;00m re\u001b[39m.\u001b[39msearch(\u001b[39m'\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+x\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+\u001b[39m\u001b[39m'\u001b[39m, l)]\n",
      "\u001b[0;31mOSError\u001b[0m: MoviePy error: failed to read the duration of file ./Datasets/Video/obamaDeepfake.mp4.\nHere are the file infos returned by ffmpeg:\n\nffmpeg version 4.2.2-static https://johnvansickle.com/ffmpeg/  Copyright (c) 2000-2019 the FFmpeg developers\n  built with gcc 8 (Debian 8.3.0-6)\n  configuration: --enable-gpl --enable-version3 --enable-static --disable-debug --disable-ffplay --disable-indev=sndio --disable-outdev=sndio --cc=gcc --enable-fontconfig --enable-frei0r --enable-gnutls --enable-gmp --enable-libgme --enable-gray --enable-libaom --enable-libfribidi --enable-libass --enable-libvmaf --enable-libfreetype --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-librubberband --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libvorbis --enable-libopus --enable-libtheora --enable-libvidstab --enable-libvo-amrwbenc --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libdav1d --enable-libxvid --enable-libzvbi --enable-libzimg\n  libavutil      56. 31.100 / 56. 31.100\n  libavcodec     58. 54.100 / 58. 54.100\n  libavformat    58. 29.100 / 58. 29.100\n  libavdevice    58.  8.100 / 58.  8.100\n  libavfilter     7. 57.100 /  7. 57.100\n  libswscale      5.  5.100 /  5.  5.100\n  libswresample   3.  5.100 /  3.  5.100\n  libpostproc    55.  5.100 / 55.  5.100\n[mov,mp4,m4a,3gp,3g2,mj2 @ 0x6936480] Format mov,mp4,m4a,3gp,3g2,mj2 detected only with low score of 1, misdetection possible!\n[mov,mp4,m4a,3gp,3g2,mj2 @ 0x6936480] moov atom not found\n./Datasets/Video/obamaDeepfake.mp4: Invalid data found when processing input\n"
     ]
    }
   ],
   "source": [
    "                                            # Extract the audio from the input video file\n",
    "\n",
    "# Insert Local Video File Path\n",
    "\n",
    "video_path = \"./Datasets/Video/obamaDeepfake.mp4\"\n",
    "clip = mp.VideoFileClip(video_path)\n",
    "    \n",
    "# Insert Local Audio File Path\n",
    "audio_path = video_path.replace('.mp4', '.wav').replace('Video', 'Audio')\n",
    "print(audio_path)\n",
    "clip.audio.write_audiofile(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
      "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMAGINE THIS FOR A SECOND ONE MAN WITH TOTAL CONTROL OF BILLIONS OF PEOPLE STOLEN DATA ALL THEIR SECRETS THEIR LIVES THEIR FUTURES I OWE IT ALL TO SPECTRE SPECTRES SHOWED ME THAT WHOEVER CONTROLS THE DATA CONTROLS THE FUTURE AN\n"
     ]
    }
   ],
   "source": [
    "# Converting Audio file to Text\n",
    "\n",
    "transcription = speech2text.speech_transcription(audio_path)\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the variable value to the text file\n",
    "text_path = video_path.replace('.mp4', '.txt').replace('Video', 'Text')\n",
    "\n",
    "with open(text_path, 'w') as file:\n",
    "    file.write(transcription.replace(' ', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling wav file from 44100 to 11025...\n",
      "SKIPPING WORD IMAGINE\n",
      "SKIPPING WORD THIS\n",
      "SKIPPING WORD FOR\n",
      "SKIPPING WORD A\n",
      "SKIPPING WORD SECOND\n",
      "SKIPPING WORD ONE\n",
      "SKIPPING WORD MAN\n",
      "SKIPPING WORD WITH\n",
      "SKIPPING WORD TOTAL\n",
      "SKIPPING WORD CONTROL\n",
      "SKIPPING WORD OF\n",
      "SKIPPING WORD BILLIONS\n",
      "SKIPPING WORD OF\n",
      "SKIPPING WORD PEOPLE\n",
      "SKIPPING WORD STOLEN\n",
      "SKIPPING WORD DATA\n",
      "SKIPPING WORD ALL\n",
      "SKIPPING WORD THEIR\n",
      "SKIPPING WORD SECRETS\n",
      "SKIPPING WORD THEIR\n",
      "SKIPPING WORD LIVES\n",
      "SKIPPING WORD THEIR\n",
      "SKIPPING WORD FUTURES\n",
      "SKIPPING WORD I\n",
      "SKIPPING WORD OWE\n",
      "SKIPPING WORD IT\n",
      "SKIPPING WORD ALL\n",
      "SKIPPING WORD TO\n",
      "SKIPPING WORD SPECTRE\n",
      "SKIPPING WORD SPECTRES\n",
      "SKIPPING WORD SHOWED\n",
      "SKIPPING WORD ME\n",
      "SKIPPING WORD THAT\n",
      "SKIPPING WORD WHOEVER\n",
      "SKIPPING WORD CONTROLS\n",
      "SKIPPING WORD THE\n",
      "SKIPPING WORD DATA\n",
      "SKIPPING WORD CONTROLS\n",
      "SKIPPING WORD THE\n",
      "SKIPPING WORD FUTURE\n",
      "SKIPPING WORD AN\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Reube\\\\AppData\\\\Local\\\\Temp\\\\p2fa\\\\aligned.mlf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-426f960baa85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Perform alignment using P2FA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mphoneme_timestamps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_timestamps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malign\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Extract the timestamps of a specific phoneme\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Reuben\\NITC\\Sem8\\Project Part 2\\deepfake-detection\\Components\\p2fa_py3\\p2fa\\align.py\u001b[0m in \u001b[0;36malign\u001b[1;34m(wavfile, trsfile, outfile, wave_start, wave_end, sr_override, model_path, custom_dict, state_align, verbose)\u001b[0m\n\u001b[0;32m    449\u001b[0m         \u001b[0mstate_alignments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m     \u001b[0m_alignments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_aligned_mlf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_mlf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwave_start\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m     \u001b[0mphoneme_alignments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_alignments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_alignment_lists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_alignments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Reuben\\NITC\\Sem8\\Project Part 2\\deepfake-detection\\Components\\p2fa_py3\\p2fa\\align.py\u001b[0m in \u001b[0;36mread_aligned_mlf\u001b[1;34m(mlffile, SR, wave_start)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;31m# TODO: extract log-likelihood score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmlffile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m     \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Reube\\\\AppData\\\\Local\\\\Temp\\\\p2fa\\\\aligned.mlf'"
     ]
    }
   ],
   "source": [
    "# Phoneme Extraction\n",
    "\n",
    "# Perform alignment using P2FA\n",
    "phoneme_timestamps, word_timestamps, pff = align.align(audio_path, text_path)\n",
    "\n",
    "# Extract the timestamps of a specific phoneme\n",
    "target_phonemes = [\"M\", \"B\", \"P\"] # Closed mouth phonemes that we want to extract\n",
    "for phoneme in target_phonemes:\n",
    "    target_phoneme_timestamps = [(start, end) for p, start, end in phoneme_timestamps if p == phoneme]\n",
    "\n",
    "# Print the timestamps of the target phoneme\n",
    "print(f\"Timestamps of '{phoneme}': {target_phoneme_timestamps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_phoneme_timestamps = [(2.6564625850340136, 2.756235827664399), (3.045578231292517, 3.1054421768707483), (6.248299319727891, 6.318140589569161), (12.30453514739229, 12.414285714285713), (16.315419501133785, 16.345351473922904), (22.840589569160993, 22.89047619047619), (24.52675736961451, 24.576643990929703), (25.48458049886621, 25.544444444444444), (34.384353741496604, 34.42426303854876), (36.040589569161, 36.070521541950114), (41.168934240362816, 41.208843537414964), (43.363945578231295, 43.41383219954648), (44.6609977324263, 44.81065759637188), (46.436961451247164, 46.50680272108844), (48.39251700680273, 48.462358276644), (53.2015873015873, 53.31133786848073), (55.45646258503402, 55.5562358276644), (58.210204081632654, 58.24013605442177), (64.19659863945579, 64.30634920634921), (64.47596371882086, 64.55578231292517)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0xb6ab140] moov atom not found\n"
     ]
    }
   ],
   "source": [
    "# Viseme Extraction\n",
    "\n",
    "#import libraires\n",
    "import cv2\n",
    "import numpy as np\n",
    "frames=viseme.extract_frames(\"./Datasets/Video/obamaDeepfake.mp4\",target_phoneme_timestamps)\n",
    "\n",
    "# Define the output folder\n",
    "frame_path = \"Datasets/Viseme_frames/\"\n",
    "\n",
    "# Loop through the frames and save them to the output folder\n",
    "for i, (frame,index,frame_seqnum) in enumerate(frames):\n",
    "    filename = \"Frame_{}_{}.jpg\".format(index,frame_seqnum)\n",
    "\n",
    "    cv2.imwrite( frame_path + filename, frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rameez/Final_Proj/deepfake-detection\n",
      "[INFO] loading facial landmark predictor...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error deserializing object of type int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# MAR Calculation\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m mar \u001b[39m=\u001b[39m mouthLabelling\u001b[39m.\u001b[39;49mmouth_aspect_ratio(frame_path)\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMouth aspect ratio: \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mlen\u001b[39m(mar), \u001b[39m\"\u001b[39m\u001b[39m items\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(mar))\n",
      "File \u001b[0;32m~/Final_Proj/deepfake-detection/Components/Mouth_Labelling/mouthLabelling.py:46\u001b[0m, in \u001b[0;36mmouth_aspect_ratio\u001b[0;34m(frames_path)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[INFO] loading facial landmark predictor...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m detector \u001b[39m=\u001b[39m dlib\u001b[39m.\u001b[39mget_frontal_face_detector()\n\u001b[0;32m---> 46\u001b[0m predictor \u001b[39m=\u001b[39m dlib\u001b[39m.\u001b[39;49mshape_predictor(\u001b[39m\"\u001b[39;49m\u001b[39m./Components/Mouth_Labelling/shape_predictor_68_face_landmarks.dat\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     48\u001b[0m \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(frames_path):\n\u001b[1;32m     49\u001b[0m     \u001b[39m# Check if the file is an image (ends with .jpg or .png)\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[39mif\u001b[39;00m filename\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.jpg\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m filename\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.png\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     51\u001b[0m         \u001b[39m# Construct the full image path\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error deserializing object of type int"
     ]
    }
   ],
   "source": [
    "# MAR Calculation\n",
    "\n",
    "mar = mouthLabelling.mouth_aspect_ratio(frame_path)\n",
    "print(\"Mouth aspect ratio: \", len(mar), \" items\")\n",
    "print(len(mar))\n",
    "for i in range(len(mar)):\n",
    "  print (mar[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mismatch Calculation\n",
    "\n",
    "MOUTH_AR_THRESH = 0.485\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "708d0409c923cfa6f55df4b87c4f6b58aca283ae12d5e8dd9802a5db19fa8d01"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
