{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to run the rudimentary design(without CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary files\n",
    "\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import librosa\n",
    "# import cv2\n",
    "import os\n",
    "import moviepy.editor as mp\n",
    "from Components.Phoneme_Extraction import speech2text\n",
    "from Components.p2fa_py3.p2fa import align\n",
    "from Components.Viseme_Extraction import viseme\n",
    "from Components.Mouth_Labelling import mouthLabelling\n",
    "from Components.Mismatch_Estimator import mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Datasets/Audio/zuckerbergDeepfake.wav\n",
      "MoviePy - Writing audio in ./Datasets/Audio/zuckerbergDeepfake.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "                                            # Extract the audio from the input video file\n",
    "\n",
    "# Insert Local Video File Path\n",
    "\n",
    "video_path = \"./Datasets/Video/obama1.mp4\"\n",
    "clip = mp.VideoFileClip(video_path)\n",
    "    \n",
    "# Insert Local Audio File Path\n",
    "audio_path = video_path.replace('.mp4', '.wav').replace('Video', 'Audio')\n",
    "print(audio_path)\n",
    "clip.audio.write_audiofile(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
      "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMAGINE THIS FOR A SECOND ONE MAN WITH TOTAL CONTROL OF BILLIONS OF PEOPLE STOLEN DATA ALL THEIR SECRETS THEIR LIVES THEIR FUTURES I OWE IT ALL TO SPECTRE SPECTRES SHOWED ME THAT WHOEVER CONTROLS THE DATA CONTROLS THE FUTURE AN\n"
     ]
    }
   ],
   "source": [
    "# Converting Audio file to Text\n",
    "\n",
    "transcription = speech2text.speech_transcription(audio_path)\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the variable value to the text file\n",
    "text_path = video_path.replace('.mp4', '.txt').replace('Video', 'Text')\n",
    "\n",
    "with open(text_path, 'w') as file:\n",
    "    file.write(transcription.replace(' ', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling wav file from 44100 to 11025...\n",
      "SKIPPING WORD SPECTRES\n",
      "/tmp/p2fa/sound.wav -> /tmp/p2fa/tmp.plp \n",
      "Timestamps of Closed Mouth: [(0.41156462585034015, 0.4913832199546485), (2.576643990929705, 2.6365079365079365), (13.581632653061224, 13.621541950113379), (4.462358276643991, 4.512244897959183), (5.060997732426303, 5.090929705215419), (5.220634920634921, 5.250566893424036), (12.833333333333332, 12.873242630385487)]\n"
     ]
    }
   ],
   "source": [
    "# Phoneme Extraction\n",
    "\n",
    "# Perform alignment using P2FA\n",
    "phoneme_timestamps, word_timestamps, pff = align.align(audio_path, text_path)\n",
    "\n",
    "# Extract the timestamps of a specific phoneme\n",
    "target_phonemes = [\"M\", \"B\", \"P\"] # Closed mouth phonemes that we want to extract\n",
    "timestamps = []\n",
    "for phoneme in target_phonemes:\n",
    "    target_phoneme_timestamps = [(start, end) for p, start, end in phoneme_timestamps if p == phoneme]\n",
    "    timestamps.extend(target_phoneme_timestamps)\n",
    "\n",
    "# Print the timestamps of the target phoneme\n",
    "print(f\"Timestamps of Closed Mouth: {timestamps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n",
      "Error: Frame number out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0xb6ab140] moov atom not found\n"
     ]
    }
   ],
   "source": [
    "# Viseme Extraction\n",
    "\n",
    "#import libraires\n",
    "import cv2\n",
    "import numpy as np\n",
    "frames=viseme.extract_frames(video_path, timestamps)\n",
    "\n",
    "# Define the output folder\n",
    "frame_path = \"Datasets/Viseme_frames/\"\n",
    "\n",
    "# Loop through the frames and save them to the output folder\n",
    "for i, (frame,index,frame_seqnum) in enumerate(frames):\n",
    "    filename = \"Frame_{}_{}.jpg\".format(index,frame_seqnum)\n",
    "\n",
    "    cv2.imwrite( frame_path + filename, frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/reubensuju/Reuben/NITC_C-GCC_Repo/Sem8/Project_Part_2/deepfake-detection\n",
      "[INFO] loading facial landmark predictor...\n",
      "Mouth aspect ratio:  42  items\n",
      "['Frame_6_2.jpg', 0.5767972674053732]\n",
      "['Frame_1_1.jpg', 0.7174527310059746]\n",
      "['Frame_3_5.jpg', 0.5915625522877966]\n",
      "['Frame_0_2.jpg', 0.5221483679937239]\n",
      "['Frame_3_4.jpg', 0.5915625522877966]\n",
      "['Frame_3_2.jpg', 0.5586043624760154]\n",
      "['Frame_0_1.jpg', 0.5096097386017643]\n",
      "['Frame_1_2.jpg', 0.7398219124831164]\n",
      "['Frame_2_5.jpg', 0.5863194699698894]\n",
      "['Frame_1_0.jpg', 0.7174527310059746]\n",
      "['Frame_3_0.jpg', 0.5249636615625813]\n",
      "['Frame_1_5.jpg', 0.7498903829190143]\n",
      "['Frame_4_0.jpg', 0.5418434750578494]\n",
      "['Frame_4_2.jpg', 0.5606139519520328]\n",
      "['Frame_2_1.jpg', 0.5504281305003996]\n",
      "['Frame_2_4.jpg', 0.5863194699698894]\n",
      "['Frame_0_3.jpg', 0.5221483679937239]\n",
      "['Frame_4_4.jpg', 0.5606139519520328]\n",
      "['Frame_6_5.jpg', 0.6658602737399514]\n",
      "['Frame_5_4.jpg', 0.4887308375627064]\n",
      "['Frame_5_2.jpg', 0.4821862716710384]\n",
      "['Frame_0_0.jpg', 0.5096097386017643]\n",
      "['Frame_1_3.jpg', 0.7398219124831164]\n",
      "['Frame_5_3.jpg', 0.4887308375627064]\n",
      "['Frame_5_1.jpg', 0.4821862716710384]\n",
      "['Frame_1_4.jpg', 0.7398219124831164]\n",
      "['Frame_6_1.jpg', 0.5767972674053732]\n",
      "['Frame_2_3.jpg', 0.5863194699698894]\n",
      "['Frame_4_3.jpg', 0.5606139519520328]\n",
      "['Frame_0_4.jpg', 0.6228529377885201]\n",
      "['Frame_4_1.jpg', 0.5606139519520328]\n",
      "['Frame_4_5.jpg', 0.5606139519520328]\n",
      "['Frame_6_3.jpg', 0.5767972674053732]\n",
      "['Frame_6_4.jpg', 0.5767972674053732]\n",
      "['Frame_2_0.jpg', 0.5504281305003996]\n",
      "['Frame_2_2.jpg', 0.5504281305003996]\n",
      "['Frame_6_0.jpg', 0.5811842387116837]\n",
      "['Frame_3_3.jpg', 0.5586043624760154]\n",
      "['Frame_3_1.jpg', 0.5586043624760154]\n",
      "['Frame_5_5.jpg', 0.4887308375627064]\n",
      "['Frame_5_0.jpg', 0.4821862716710384]\n",
      "['Frame_0_5.jpg', 0.6228529377885201]\n"
     ]
    }
   ],
   "source": [
    "# MAR Calculation\n",
    "\n",
    "mar = mouthLabelling.mouth_aspect_ratio(frame_path)\n",
    "print(\"Mouth aspect ratio: \", len(mar), \" items\")\n",
    "print(len(mar))\n",
    "for i in range(len(mar)):\n",
    "  print (mar[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.50960974 0.50960974 0.52214837 0.52214837 0.62285294 0.62285294]\n",
      " [0.71745273 0.71745273 0.73982191 0.73982191 0.73982191 0.74989038]\n",
      " [0.55042813 0.55042813 0.55042813 0.58631947 0.58631947 0.58631947]\n",
      " [0.52496366 0.55860436 0.55860436 0.55860436 0.59156255 0.59156255]\n",
      " [0.54184348 0.56061395 0.56061395 0.56061395 0.56061395 0.56061395]\n",
      " [0.48218627 0.48218627 0.48218627 0.48873084 0.48873084 0.48873084]\n",
      " [0.58118424 0.57679727 0.57679727 0.57679727 0.57679727 0.66586027]]\n"
     ]
    }
   ],
   "source": [
    "def extract_num(frame):\n",
    "    return int(frame[0].split(\"_\")[1]), int(frame[0].split(\"_\")[2].split(\".\")[0])\n",
    "\n",
    "# Sort frames based on numerical value in filename\n",
    "mar.sort(key=lambda frame: (extract_num(frame)[0], extract_num(frame)[1]))\n",
    "\n",
    "num_rows = len(mar) // 6  # Compute number of rows required\n",
    "# Initialize 2D array with zeros\n",
    "mar_values = np.zeros((num_rows, 6))\n",
    "\n",
    "# Loop through sorted frames list and populate 2D array\n",
    "for i, frame in enumerate(mar):\n",
    "    row = i // 6  # Compute row index\n",
    "    col = i % 6   # Compute column index\n",
    "    mar_values[row][col] = frame[1]\n",
    "\n",
    "# Print 2D array\n",
    "print(mar_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.285714285714285\n"
     ]
    }
   ],
   "source": [
    "# Mismatch Calculation\n",
    "\n",
    "MOUTH_AR_THRESH = 0.485\n",
    "\n",
    "error_rate = mismatch.calculate_mismatch_error_rate(mar_values, MOUTH_AR_THRESH)\n",
    "print(error_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "708d0409c923cfa6f55df4b87c4f6b58aca283ae12d5e8dd9802a5db19fa8d01"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
