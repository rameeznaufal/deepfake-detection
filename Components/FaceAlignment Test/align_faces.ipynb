{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't parse 'center'. Sequence item with index 0 has a wrong type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m (x, y, w, h) \u001b[39m=\u001b[39m rect_to_bb(rect)\n\u001b[0;32m     36\u001b[0m faceOrig \u001b[39m=\u001b[39m imutils\u001b[39m.\u001b[39mresize(image[y:y \u001b[39m+\u001b[39m h, x:x \u001b[39m+\u001b[39m w], width\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m faceAligned \u001b[39m=\u001b[39m fa\u001b[39m.\u001b[39;49malign(image, gray, rect)\n\u001b[0;32m     38\u001b[0m \u001b[39m# display the output images\u001b[39;00m\n\u001b[0;32m     39\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m\"\u001b[39m\u001b[39mOriginal\u001b[39m\u001b[39m\"\u001b[39m, faceOrig)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Desktop\\Deepfake\\deepfake-detection\\Components\\venv\\lib\\site-packages\\imutils\\face_utils\\facealigner.py:68\u001b[0m, in \u001b[0;36mFaceAligner.align\u001b[1;34m(self, image, gray, rect)\u001b[0m\n\u001b[0;32m     64\u001b[0m eyesCenter \u001b[39m=\u001b[39m ((leftEyeCenter[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m rightEyeCenter[\u001b[39m0\u001b[39m]) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m,\n\u001b[0;32m     65\u001b[0m \t(leftEyeCenter[\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m rightEyeCenter[\u001b[39m1\u001b[39m]) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m)\n\u001b[0;32m     67\u001b[0m \u001b[39m# grab the rotation matrix for rotating and scaling the face\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m M \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mgetRotationMatrix2D(eyesCenter, angle, scale)\n\u001b[0;32m     70\u001b[0m \u001b[39m# update the translation component of the matrix\u001b[39;00m\n\u001b[0;32m     71\u001b[0m tX \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdesiredFaceWidth \u001b[39m*\u001b[39m \u001b[39m0.5\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: Can't parse 'center'. Sequence item with index 0 has a wrong type"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from imutils.face_utils import FaceAligner\n",
    "from imutils.face_utils import rect_to_bb\n",
    "import argparse\n",
    "import imutils\n",
    "import dlib\n",
    "import cv2\n",
    "# construct the argument parser and parse the arguments\n",
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument(\"-p\", \"--shape-predictor\", required=True,\n",
    "# help=\"path to facial landmark predictor\")\n",
    "# ap.add_argument(\"-i\", \"--image\", required=True,\n",
    "# help=\"path to input image\")\n",
    "# args = vars(ap.parse_args())\n",
    "\n",
    "# initialize dlib's face detector (HOG-based) and then create\n",
    "# the facial landmark predictor and the face aligner\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "fa = FaceAligner(predictor, desiredFaceWidth=256)\n",
    "\n",
    "# load the input image, resize it, and convert it to grayscale\n",
    "image = cv2.imread(\"frame_84.jpg\")\n",
    "image = imutils.resize(image, width=800)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# show the original input image and detect faces in the grayscale\n",
    "# image\n",
    "cv2.imshow(\"Input\", image)\n",
    "rects = detector(gray, 2)\n",
    "\n",
    "# loop over the face detections\n",
    "for rect in rects:\n",
    "\t# extract the ROI of the *original* face, then align the face\n",
    "\t# using facial landmarks\n",
    "\t(x, y, w, h) = rect_to_bb(rect)\n",
    "\tfaceOrig = imutils.resize(image[y:y + h, x:x + w], width=256)\n",
    "\tfaceAligned = fa.align(image, gray, rect)\n",
    "\t# display the output images\n",
    "\tcv2.imshow(\"Original\", faceOrig)\n",
    "\tcv2.imshow(\"Aligned\", faceAligned)\n",
    "\tcv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5 (tags/v3.9.5:0a7dcbd, May  3 2021, 17:27:52) [MSC v.1928 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "65f0376e53f64dc0830bdf4e1e0f1cda09c8e2cd15e90a6fa5827398e6ad0a59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
